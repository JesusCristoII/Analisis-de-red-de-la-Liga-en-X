{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_browser():\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get('https://x.com/i/flow/login?lang=es')\n",
    "    browser.maximize_window()\n",
    "    return browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapping(browser, correo, username, password, busquedas):\n",
    "    df = pd.DataFrame({'Source': [], 'Target': []})\n",
    "    wait = WebDriverWait(browser, 90)\n",
    "\n",
    "    # Hacer log-in en twitter\n",
    "    boton_correo = wait.until(EC.presence_of_element_located((By.XPATH,\n",
    "    '//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/div[4]/label/div/div[2]/div/input')))\n",
    "    boton_correo.send_keys(correo)\n",
    "\n",
    "    boton_next = wait.until(EC.element_to_be_clickable((By.XPATH,\n",
    "    '//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div/div/div/button[2]')))\n",
    "    boton_next.click()\n",
    "\n",
    "    try:\n",
    "        boton_username = wait.until(EC.presence_of_element_located((By.XPATH,\n",
    "        '//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div[2]/label/div/div[2]/div/input')))\n",
    "        boton_username.send_keys(username)\n",
    "\n",
    "        boton_next2 = wait.until(EC.element_to_be_clickable((By.XPATH,\n",
    "        '//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div/div/div/button')))\n",
    "        boton_next2.click()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    boton_password = wait.until(EC.presence_of_element_located((By.XPATH,\n",
    "    '//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[1]/div/div/div[3]/div/label/div/div[2]/div[1]/input')))\n",
    "    boton_password.send_keys(password)\n",
    "\n",
    "    boton_login = wait.until(EC.element_to_be_clickable((By.XPATH,\n",
    "    '//*[@id=\"layers\"]/div/div/div/div/div/div/div[2]/div[2]/div/div/div[2]/div[2]/div[2]/div/div/div/div/button')))\n",
    "    boton_login.click()\n",
    "\n",
    "    # Acepta las cookies\n",
    "    boton_cookies = wait.until(EC.element_to_be_clickable((By.XPATH,\n",
    "    '//*[@id=\"layers\"]/div/div/div/div/div/div[2]/button[1]')))\n",
    "    boton_cookies.click()\n",
    "\n",
    "    for busqueda in busquedas:\n",
    "        # Hacer búsqueda con una palabra clave\n",
    "        browser.get('https://x.com/search?q=' + busqueda + '&src=typed_query')\n",
    "        \n",
    "        tweets_distintos = []\n",
    "        \n",
    "        # Recolecta tweets\n",
    "        while len(tweets_distintos) < 20:\n",
    "            \n",
    "            browser.execute_script(\"window.scrollBy({ top: 800, behavior: 'smooth' })\")\n",
    "            time.sleep(2)\n",
    "            try:\n",
    "                tweets = wait.until(EC.presence_of_all_elements_located((By.XPATH, \"//article[@data-testid='tweet']//div[@data-testid='tweetText']\")))\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            for tweet in tweets:\n",
    "                try:\n",
    "                    tweet_link = tweet.find_element(By.XPATH,\n",
    "                    \"//div[@class='css-175oi2r r-18u37iz r-1wbh5a2 r-1ez5h0i']//div[@class='css-175oi2r r-18u37iz r-1q142lx']//a[@role='link']\").get_attribute('href')\n",
    "                    autor = re.search(r'https://x.com/(.*)/status/.*', tweet_link).group(1)\n",
    "                    if tweet_link not in tweets_distintos:\n",
    "                        tweets_distintos.append(tweet_link)\n",
    "                        browser.get(tweet_link)\n",
    "\n",
    "                        # Obtiene las respuestas de los tweets\n",
    "                        respuestas = []\n",
    "                        last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                        while True:\n",
    "                            time.sleep(3)\n",
    "                            usernames = browser.find_elements(By.XPATH,\n",
    "                            \"//article[@data-testid='tweet']//div[@class='css-175oi2r r-zl2h9q']//div[@class='css-175oi2r r-18u37iz r-1wbh5a2 r-1ez5h0i']//span[@class='css-1jxf684 r-bcqeeo r-1ttztb7 r-qvutc0 r-poiln3']\")\n",
    "                            respuestas.extend([name_div.text[1:] for name_div in usernames if name_div.text[0] == '@'])\n",
    "                            browser.execute_script(\"window.scrollBy(0, document.body.scrollHeight)\")\n",
    "                            new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                            if new_height == last_height:\n",
    "                                break\n",
    "                            last_height = new_height\n",
    "                        respuestas = list(set(respuestas))\n",
    "                            \n",
    "                        df2 = pd.DataFrame({'usuario1': autor, 'usuario2': respuestas})\n",
    "                        df = pd.concat([df, df2], ignore_index=True)\n",
    "                        \n",
    "                        browser.back()\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Alavés\" min_replies:10 lang:es',\n",
       " '\"Athletic Club\" min_replies:10 lang:es',\n",
       " '\"Atlético de Madrid\" min_replies:10 lang:es',\n",
       " '\"FC Barcelona\" min_replies:10 lang:es',\n",
       " '\"Celta de Vigo\" min_replies:10 lang:es',\n",
       " '\"Espanyol\" min_replies:10 lang:es',\n",
       " '\"Getafe CF\" min_replies:10 lang:es',\n",
       " '\"Girona FC\" min_replies:10 lang:es',\n",
       " '\"UD Las Palmas\" min_replies:10 lang:es',\n",
       " '\"CD Leganés\" min_replies:10 lang:es',\n",
       " '\"Real Mallorca\" min_replies:10 lang:es',\n",
       " '\"Osasuna\" min_replies:10 lang:es',\n",
       " '\"Rayo Vallecano\" min_replies:10 lang:es',\n",
       " '\"Real Betis\" min_replies:10 lang:es',\n",
       " '\"Real Madrid\" min_replies:10 lang:es',\n",
       " '\"Real Sociedad\" min_replies:10 lang:es',\n",
       " '\"Real Valladolid\" min_replies:10 lang:es',\n",
       " '\"Sevilla FC\" min_replies:10 lang:es',\n",
       " '\"Valencia CF\" min_replies:10 lang:es',\n",
       " 'Villarreal LaLiga min_replies:10 lang:es']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correo = 'pruebatwiter2@gmail.com'\n",
    "username = 'pruebatwiter02'\n",
    "password = 'passpruebatwiter2'\n",
    "\n",
    "equipos = [\n",
    "    '\"Alavés\"',\n",
    "    '\"Athletic Club\"',\n",
    "    '\"Atlético de Madrid\"',\n",
    "    '\"FC Barcelona\"',\n",
    "    '\"Celta de Vigo\"',\n",
    "    '\"Espanyol\"',\n",
    "    '\"Getafe CF\"',\n",
    "    '\"Girona FC\"',\n",
    "    '\"UD Las Palmas\"',\n",
    "    '\"CD Leganés\"',\n",
    "    '\"Real Mallorca\"',\n",
    "    '\"Osasuna\"',\n",
    "    '\"Rayo Vallecano\"',\n",
    "    '\"Real Betis\"',\n",
    "    '\"Real Madrid\"',\n",
    "    '\"Real Sociedad\"',\n",
    "    '\"Real Valladolid\"',\n",
    "    '\"Sevilla FC\"',\n",
    "    '\"Valencia CF\"',\n",
    "    'Villarreal LaLiga'\n",
    "]\n",
    "busquedas = [f'{equipo}' + ' min_replies:10 lang:es' for equipo in equipos]\n",
    "busquedas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = start_browser()\n",
    "df = scrapping(browser, correo, username, password, busquedas)\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('red_social.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
